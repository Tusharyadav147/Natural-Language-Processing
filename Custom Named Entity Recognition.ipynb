{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1957a96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# importing the model en_core_web_sm of English for vocabluary, syntax & entities\n",
    "import en_core_web_sm   \n",
    "\n",
    "# load en_core_web_sm of English for vocabluary, syntax & entities\n",
    "nlp = en_core_web_sm.load() \n",
    "\n",
    "#  \"nlp\" Object is used to create documents with linguistic annotations.\n",
    "doc = nlp('what is the price of mcspicy chicken?')\n",
    "\n",
    "entities=[(i, i.label_) for i in doc.ents]\n",
    "\n",
    "print(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f13180f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required libraries\n",
    "import spacy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9a69e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial parameters\n",
    "model_file = None # set esisting model name other wise set it to None\n",
    "iterations = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5dd1ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "TRAINING_DATA = [('what is the price of McVeggie?', {'entities': [(21, 29, 'FoodProduct')]}), \n",
    "                 ('what is the price of McEgg?', {'entities': [(21, 26, 'FoodProduct')]}), \n",
    "                 ('what is the price of McChicken?', {'entities': [(21, 30, 'FoodProduct')]}), \n",
    "                 ('what is the price of McSpicy Paneer?', {'entities': [(21, 35, 'FoodProduct')]}), \n",
    "                 ('what is the price of McSpicy Chicken?', {'entities': [(21, 36, 'FoodProduct')]}),] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85ae7984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created blank NLP model\n"
     ]
    }
   ],
   "source": [
    "# Testing sample data       \n",
    "test_sample='what is the price of McAloo?'\n",
    "\n",
    "# Create NLP model\n",
    "if model_file is not None:\n",
    "    nlp = spacy.load(model_file)  \n",
    "    print(\"Load Existing NER Model \", model_file)\n",
    "else:\n",
    "    nlp = spacy.blank('en')  \n",
    "    print(\"Created blank NLP model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd9791f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create NLP Pipeline\n",
    "if 'ner' not in nlp.pipe_names: \n",
    "    nlp.add_pipe('ner')\n",
    "else:\n",
    "    ner_pipe = nlp.get_pipe('ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59337596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add entities labels to the ner pipeline\n",
    "for text, annotations in TRAINING_DATA:\n",
    "    for entity in annotations.get('entities'):\n",
    "        ner_pipe.add_label(entity[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "951bf6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Number:0\n",
      "Loss: 26.925736516714096\n",
      "Iteration Number:1\n",
      "Loss: 10.360803883813787\n",
      "Iteration Number:2\n",
      "Loss: 7.664226388217872\n",
      "Iteration Number:3\n",
      "Loss: 7.554177849869799\n",
      "Iteration Number:4\n",
      "Loss: 3.5146913069742363\n",
      "Iteration Number:5\n",
      "Loss: 2.235378855385953\n",
      "Iteration Number:6\n",
      "Loss: 1.4391341406213742\n",
      "Iteration Number:7\n",
      "Loss: 3.370807148093064\n",
      "Iteration Number:8\n",
      "Loss: 3.39401508519824\n",
      "Iteration Number:9\n",
      "Loss: 1.5366774841387107\n",
      "Iteration Number:10\n",
      "Loss: 0.016965338063723398\n",
      "Iteration Number:11\n",
      "Loss: 0.0004255714508232036\n",
      "Iteration Number:12\n",
      "Loss: 0.0039022217737479364\n",
      "Iteration Number:13\n",
      "Loss: 0.00010787500000543969\n",
      "Iteration Number:14\n",
      "Loss: 1.5120197009993195e-06\n",
      "Iteration Number:15\n",
      "Loss: 1.3886151551261622e-05\n",
      "Iteration Number:16\n",
      "Loss: 5.66273864695841e-07\n",
      "Iteration Number:17\n",
      "Loss: 1.908502045253412e-06\n",
      "Iteration Number:18\n",
      "Loss: 2.8461840056911967e-07\n",
      "Iteration Number:19\n",
      "Loss: 8.033790172864669e-08\n",
      "Iteration Number:20\n",
      "Loss: 1.1663018478796077e-05\n",
      "Iteration Number:21\n",
      "Loss: 4.5703654517657925e-08\n",
      "Iteration Number:22\n",
      "Loss: 4.924015824824571e-07\n",
      "Iteration Number:23\n",
      "Loss: 8.199511321409599e-07\n",
      "Iteration Number:24\n",
      "Loss: 4.110762608075622e-06\n"
     ]
    }
   ],
   "source": [
    "from spacy.training.example import Example\n",
    "\n",
    "# get names of other pipes to disable them during training\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']# train NER Model\n",
    "\n",
    "with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "    optimizer = nlp.begin_training()\n",
    "    for itn in range(iterations):\n",
    "        print(\"Iteration Number:\" + str(itn))\n",
    "        random.shuffle(TRAINING_DATA)\n",
    "        losses = {}\n",
    "        for text, annotations in TRAINING_DATA:\n",
    "            # create example object\n",
    "            example = Example.from_dict(nlp.make_doc(text), annotations) # batch of texts and annotations\n",
    "            nlp.update([example],  \n",
    "                drop=0.2,# dropout - make it harder to memorise data\n",
    "                sgd=optimizer,  # callable to update weights\n",
    "                losses=losses)\n",
    "        print(\"Loss:\",losses['ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0cc5e996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what is the price of McAloo?'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "02ce58e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(McAloo, 'FoodProduct')]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(test_sample)\n",
    "\n",
    "entities=[(i, i.label_) for i in doc.ents]\n",
    "\n",
    "print(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6a23a174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "McAloo 21 27 FoodProduct\n"
     ]
    }
   ],
   "source": [
    "# save model\n",
    "model_file =\"ner_model\"\n",
    "nlp.to_disk(model_file)# test model\n",
    "\n",
    "\n",
    "test_document = nlp(test_sample)\n",
    "for ent in test_document.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0c9f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "adf78ea0",
   "metadata": {},
   "source": [
    "## Getting start and end index for entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "28b531a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "news=\"\"\"The Supreme Court on Sunday issued a slew of directions to the Central and state governments on the COVID-19 situation and directed that no patient shall be denied hospitalisation or essential drugs in any State or Union Territory for lack of local residential or identity proof.\n",
    "Bench headed by Justice DY Chandrachud directed the Central government to formulate a national policy on admissions to hospitals, within two weeks, which shall be followed by all state governments and till then no patients will be denied admission or essential drugs in absence of local residential or identity proof.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c1f806fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supreme Court 4 17\n",
      "Justice DY Chandrachud 296 318\n",
      "Central government 332 350\n"
     ]
    }
   ],
   "source": [
    "l=['Supreme Court','Justice DY Chandrachud','Central government']\n",
    "for i in l:\n",
    "    st=news.index(i)\n",
    "    en=st+len(i)\n",
    "    print(i,st,en)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfea17f5",
   "metadata": {},
   "source": [
    "## Example - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5abb145b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPECIFY THE NER TRAINING DATA\n",
    "TRAINING_DATA = [\n",
    "        (\"I have deposited an amount of $500 using my debit card.\",{\"entities\":[(7,16,\"action\"),(30,34,\"amount\")]}),\n",
    "        (\"Send $500 to the merchant with account number 1234567890. \",{\"entities\":[(0,4,\"action\"),(5,9,\"amount\")]}),\n",
    "        (\"Transfer $20000 to my new bank account ending with the number 4567. \",{\"entities\":[(0,8,\"action\"),(9,15,\"amount\")]}),\n",
    "        (\"Please deposit $2000 in my account. \",{\"entities\":[(7,14,\"action\"),(15,20,\"amount\")]}),\n",
    "        (\"I would like to withdraw $10000 from my bank account. \",{\"entities\":[(16,24,\"action\"),(25,31,\"amount\")]})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f59467ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank('en') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cfa1f936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create NLP Pipeline\n",
    "if 'ner' not in nlp.pipe_names: \n",
    "    ner_pipe = nlp.add_pipe('ner')\n",
    "else:\n",
    "    ner_pipe = nlp.get_pipe('ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2c794aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add entities labels to the ner pipeline\n",
    "for text, annotations in TRAINING_DATA:\n",
    "    for entity in annotations.get('entities'):\n",
    "        ner_pipe.add_label(entity[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bb9310bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Number:0\n",
      "Loss: 49.097098767757416\n",
      "Iteration Number:1\n",
      "Loss: 35.938131004571915\n",
      "Iteration Number:2\n",
      "Loss: 19.31037644483149\n",
      "Iteration Number:3\n",
      "Loss: 13.757648970356968\n",
      "Iteration Number:4\n",
      "Loss: 23.97635610733414\n",
      "Iteration Number:5\n",
      "Loss: 12.094797844431014\n",
      "Iteration Number:6\n",
      "Loss: 6.334138346937834\n",
      "Iteration Number:7\n",
      "Loss: 2.613179844462138\n",
      "Iteration Number:8\n",
      "Loss: 0.584887942298856\n",
      "Iteration Number:9\n",
      "Loss: 0.43555951489860917\n",
      "Iteration Number:10\n",
      "Loss: 0.0025288696021790224\n",
      "Iteration Number:11\n",
      "Loss: 5.3008145413680556e-06\n",
      "Iteration Number:12\n",
      "Loss: 3.5749756995299323e-06\n",
      "Iteration Number:13\n",
      "Loss: 0.4051954085717397\n",
      "Iteration Number:14\n",
      "Loss: 6.736322997678397e-07\n",
      "Iteration Number:15\n",
      "Loss: 2.9925313665385765e-05\n",
      "Iteration Number:16\n",
      "Loss: 3.9259603301861517e-05\n",
      "Iteration Number:17\n",
      "Loss: 8.611520746262742e-05\n",
      "Iteration Number:18\n",
      "Loss: 3.8625380422768737e-07\n",
      "Iteration Number:19\n",
      "Loss: 1.962152189390658e-08\n",
      "Iteration Number:20\n",
      "Loss: 3.822269094814336e-07\n",
      "Iteration Number:21\n",
      "Loss: 2.2647371848965797e-07\n",
      "Iteration Number:22\n",
      "Loss: 8.904286876346363e-07\n",
      "Iteration Number:23\n",
      "Loss: 0.00011971985457597869\n",
      "Iteration Number:24\n",
      "Loss: 9.063668733987364e-09\n"
     ]
    }
   ],
   "source": [
    "from spacy.training.example import Example\n",
    "\n",
    "# get names of other pipes to disable them during training\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']# train NER Model\n",
    "\n",
    "with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "    optimizer = nlp.begin_training()\n",
    "    for itn in range(iterations):\n",
    "        print(\"Iteration Number:\" + str(itn))\n",
    "        random.shuffle(TRAINING_DATA)\n",
    "        losses = {}\n",
    "        for text, annotations in TRAINING_DATA:\n",
    "            # create example object\n",
    "            example = Example.from_dict(nlp.make_doc(text), annotations) # batch of texts and annotations\n",
    "            nlp.update([example],  \n",
    "                drop=0.2,# dropout - make it harder to memorise data\n",
    "                sgd=optimizer,  # callable to update weights\n",
    "                losses=losses)\n",
    "        print(\"Loss:\",losses['ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5aee0736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action withdrawn\n",
      "amount $300\n"
     ]
    }
   ],
   "source": [
    "doc2 = nlp(\"I have withdrawn an amount of $300 with my credit card.\")\n",
    "for ent in doc2.ents:\n",
    "    print(ent.label_, ent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2995098",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
