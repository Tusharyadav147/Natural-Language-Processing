{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b9af817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import os.path\n",
    "from gensim import corpora\n",
    "from gensim.models import LsiModel # LSA\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fe506d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path,file_name):\n",
    "    \"\"\"\n",
    "    Input  : path and file_name\n",
    "    Purpose: loading text file\n",
    "    Output : list of paragraphs/documents and \n",
    "             title(initial 100 words considred as title of document)\n",
    "    \"\"\"\n",
    "    documents_list = []\n",
    "    titles=[]\n",
    "    with open( os.path.join(path, file_name) ,\"r\") as fin:\n",
    "        for line in fin.readlines():\n",
    "            text = line.strip()\n",
    "            documents_list.append(text)\n",
    "    print(\"Total Number of Documents:\",len(documents_list))\n",
    "    titles.append( text[0:min(len(text),100)] )\n",
    "    return documents_list,titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a07b10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(doc_set):\n",
    "    \"\"\"\n",
    "    Input  : docuemnt list\n",
    "    Purpose: preprocess text (tokenize, removing stopwords, and stemming)\n",
    "    Output : preprocessed text\n",
    "    \"\"\"\n",
    "    # initialize regex tokenizer\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    # create English stop words list\n",
    "    en_stop = set(stopwords.words('english'))\n",
    "    # Create p_stemmer of class PorterStemmer\n",
    "    p_stemmer = PorterStemmer()\n",
    "    # list for tokenized documents in loop\n",
    "    texts = []\n",
    "    # loop through document list\n",
    "    for i in doc_set:\n",
    "        # clean and tokenize document string\n",
    "        raw = i.lower()\n",
    "        tokens = tokenizer.tokenize(raw)\n",
    "        # remove stop words from tokens\n",
    "        stopped_tokens = [i for i in tokens if not i in en_stop]\n",
    "        # stem tokens\n",
    "        stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]\n",
    "        # add tokens to list\n",
    "        texts.append(stemmed_tokens)\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8db8a8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_corpus(doc_clean):\n",
    "    \"\"\"\n",
    "    Input  : clean document\n",
    "    Purpose: create term dictionary of our courpus and Converting list of documents (corpus) into Document Term Matrix\n",
    "    Output : term dictionary and Document Term Matrix\n",
    "    \"\"\"\n",
    "    # Creating the term dictionary of our courpus, where every unique term is assigned an index. dictionary = corpora.Dictionary(doc_clean)\n",
    "    dictionary = corpora.Dictionary(doc_clean)\n",
    "    # Converting list of documents (corpus) into Document Term Matrix using dictionary prepared above.\n",
    "    doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]\n",
    "    # generate LDA model\n",
    "    return dictionary,doc_term_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2432879f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gensim_lsa_model(doc_clean,number_of_topics,words): \n",
    "    \"\"\"\n",
    "    Input  : clean document, number of topics and number of words associated with each topic\n",
    "    Purpose: create LSA model using gensim\n",
    "    Output : return LSA model\n",
    "    \"\"\"\n",
    "    dictionary,doc_term_matrix=prepare_corpus(doc_clean)\n",
    "    # generate LSA model\n",
    "    lsamodel = LsiModel(doc_term_matrix, num_topics=number_of_topics, id2word = dictionary)  # train model\n",
    "    topic_list = lsamodel.print_topics(num_topics=number_of_topics, num_words=words)\n",
    "    print(topic_list)\n",
    "    return lsamodel,topic_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370e4c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, doc_term_matrix, doc_clean, stop, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Input   : dictionary : Gensim dictionary\n",
    "              corpus : Gensim corpus\n",
    "              texts : List of input texts\n",
    "              stop : Max num of topics\n",
    "    purpose : Compute c_v coherence for various number of topics\n",
    "    Output  : model_list : List of LSA topic models\n",
    "              coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, stop, step):\n",
    "        # generate LSA model\n",
    "        model = LsiModel(doc_term_matrix, num_topics=num_topics, id2word = dictionary)  # train model\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=doc_clean, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0e0088",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(doc_clean,start, stop, step):\n",
    "    dictionary,doc_term_matrix=prepare_corpus(doc_clean)\n",
    "    model_list, coherence_values = compute_coherence_values(dictionary, doc_term_matrix,doc_clean,\n",
    "                                                            stop, start, step)\n",
    "    # Show graph\n",
    "    x = range(start, stop, step)\n",
    "    plt.plot(x, coherence_values)\n",
    "    plt.xlabel(\"Number of Topics\")\n",
    "    plt.ylabel(\"Coherence score\")\n",
    "    plt.legend((\"coherence_values\"), loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb4c1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_list,titles=load_data(\"\",\"articles.txt\")\n",
    "clean_text=preprocess_data(document_list)\n",
    "\n",
    "start,stop,step=2,12,1 \n",
    "plot_graph(clean_text,start,stop,step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daa9c583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Documents: 4551\n"
     ]
    }
   ],
   "source": [
    "# LSA Model\n",
    "number_of_topics = 7\n",
    "words = 10\n",
    "\n",
    "document_list,titles=load_data(\"\",\"articles.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b614ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Barclays' defiance of US fines has merit Barclays disgraced itself in many ways during the pre-financial crisis boom years. So it is tempting to think the bank, when asked by US Department of Justice to pay a large bill for polluting the financial system with mortgage junk between 2005 and 2007, should cough up, apologise and learn some humility. That is not the view of the chief executive, Jes Staley. Barclays thinks the DoJ’s claims are “disconnected from the facts” and that it has “an obligation to our shareholders, customers, clients and employees to defend ourselves against unreasonable allegations and demands.” The stance is possibly foolhardy, since going into open legal battle with the most powerful US prosecutor is risky, especially if you end up losing. But actually, some grudging respect for Staley and Barclays is in order. The US system for dishing out fines to errant banks for their mortgage sins has come to resemble a casino. The approach prefers settlements behind closed doors and the difference in size of penalties is never explained. Occasional leaks of the negotiating demands make the methodology appear even more arbitrary. Deutsche Bank was initially asked for $14bn (£11.5bn), but reached a settlement of $7.2bn on Thursday. Where is the rhyme or reason? There is also a strong suspicion that the roulette wheel is weighted against the Europeans. US banks, in the forms of JP Morgan, Goldman Sachs, Morgan Stanley, Bank of America and Citi, were at the front of the queue for settlement for no obvious reason. If Barclays created and distributed far fewer toxic mortgage securities than its US rivals, which is what the bank argues, why shouldn’t its fine be proportionately smaller? Neither Barclays nor the DoJ is talking hard numbers. But Barclays, it is said, was asked for $4bn, versus its own analysis that a fair sum would be $1bn and $2bn could have been swallowed for the sake of certainty. When the gap is so wide, Barclays is entitled to take its chances in court – and yes, it probably has an obligation to do so. A board can’t let $2bn slip out of the door just for the sake of a quiet life. The case will be messy, inevitably. Barclays’ practices were “plainly irresponsible and dishonest,” according to Loretta Lynch, the US attorney general. There is also a cache of ugly emails and documents. The DoJ lawsuit says Barclays employees called one parcel of securitised loans “craptacular”. Another was said to “look like shit”. However, that is almost par for the course in these cases. The central question is the right size of penalty. If Barclays thinks it has been singled out for unduly harsh treatment, the bank should try to prove its case. Staley will look like a fool if he fails, but the willingness to reject the easy option of settling is entirely legitimate.\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_list[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3d0aaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text=preprocess_data(document_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfd5ab3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.361*\"trump\" + 0.272*\"say\" + 0.233*\"said\" + 0.166*\"would\" + 0.160*\"clinton\" + 0.140*\"peopl\" + 0.136*\"one\" + 0.126*\"campaign\" + 0.123*\"year\" + 0.110*\"time\"'), (1, '-0.389*\"citi\" + -0.370*\"v\" + -0.356*\"h\" + -0.355*\"2016\" + -0.354*\"2017\" + -0.164*\"unit\" + -0.159*\"west\" + -0.157*\"manchest\" + -0.116*\"apr\" + -0.112*\"dec\"'), (2, '0.612*\"trump\" + 0.264*\"clinton\" + -0.261*\"eu\" + -0.148*\"say\" + -0.137*\"would\" + 0.135*\"donald\" + -0.134*\"leav\" + -0.134*\"uk\" + 0.119*\"republican\" + -0.110*\"cameron\"'), (3, '0.400*\"min\" + -0.261*\"eu\" + 0.183*\"goal\" + 0.152*\"ball\" + 0.132*\"play\" + -0.128*\"said\" + -0.128*\"say\" + 0.126*\"leagu\" + -0.122*\"leav\" + 0.122*\"game\"'), (4, '-0.404*\"bank\" + 0.305*\"eu\" + 0.290*\"min\" + -0.189*\"year\" + 0.164*\"leav\" + 0.153*\"cameron\" + -0.143*\"market\" + -0.140*\"rate\" + 0.139*\"vote\" + 0.133*\"say\"'), (5, '-0.310*\"bank\" + 0.307*\"say\" + 0.221*\"peopl\" + -0.203*\"trump\" + -0.166*\"1\" + -0.164*\"min\" + -0.163*\"0\" + -0.152*\"eu\" + -0.152*\"market\" + 0.138*\"like\"'), (6, '-0.570*\"say\" + -0.237*\"min\" + 0.170*\"vote\" + -0.158*\"govern\" + 0.154*\"poll\" + -0.122*\"tax\" + -0.115*\"bank\" + -0.114*\"statement\" + -0.112*\"budget\" + 0.108*\"one\"')]\n",
      "CPU times: user 7.27 s, sys: 217 ms, total: 7.49 s\n",
      "Wall time: 4.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model, topic_list=create_gensim_lsa_model(clean_text,number_of_topics,words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50dc1144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic- 0 : 0.361*\"trump\" + 0.272*\"say\" + 0.233*\"said\" + 0.166*\"would\" + 0.160*\"clinton\" + 0.140*\"peopl\" + 0.136*\"one\" + 0.126*\"campaign\" + 0.123*\"year\" + 0.110*\"time\"\n",
      "Topic- 1 : -0.389*\"citi\" + -0.370*\"v\" + -0.356*\"h\" + -0.355*\"2016\" + -0.354*\"2017\" + -0.164*\"unit\" + -0.159*\"west\" + -0.157*\"manchest\" + -0.116*\"apr\" + -0.112*\"dec\"\n",
      "Topic- 2 : 0.612*\"trump\" + 0.264*\"clinton\" + -0.261*\"eu\" + -0.148*\"say\" + -0.137*\"would\" + 0.135*\"donald\" + -0.134*\"leav\" + -0.134*\"uk\" + 0.119*\"republican\" + -0.110*\"cameron\"\n",
      "Topic- 3 : 0.400*\"min\" + -0.261*\"eu\" + 0.183*\"goal\" + 0.152*\"ball\" + 0.132*\"play\" + -0.128*\"said\" + -0.128*\"say\" + 0.126*\"leagu\" + -0.122*\"leav\" + 0.122*\"game\"\n",
      "Topic- 4 : -0.404*\"bank\" + 0.305*\"eu\" + 0.290*\"min\" + -0.189*\"year\" + 0.164*\"leav\" + 0.153*\"cameron\" + -0.143*\"market\" + -0.140*\"rate\" + 0.139*\"vote\" + 0.133*\"say\"\n",
      "Topic- 5 : -0.310*\"bank\" + 0.307*\"say\" + 0.221*\"peopl\" + -0.203*\"trump\" + -0.166*\"1\" + -0.164*\"min\" + -0.163*\"0\" + -0.152*\"eu\" + -0.152*\"market\" + 0.138*\"like\"\n",
      "Topic- 6 : -0.570*\"say\" + -0.237*\"min\" + 0.170*\"vote\" + -0.158*\"govern\" + 0.154*\"poll\" + -0.122*\"tax\" + -0.115*\"bank\" + -0.114*\"statement\" + -0.112*\"budget\" + 0.108*\"one\"\n"
     ]
    }
   ],
   "source": [
    "for topic, words in topic_list:\n",
    "    print('Topic-',topic,':', words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fd9b76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
