{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "140245a8",
   "metadata": {},
   "source": [
    "## Jaccard Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4c186dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'i', 'like', 'dogs.'} {'i', 'dogs.', 'hate'}\n"
     ]
    }
   ],
   "source": [
    "# documents\n",
    "doc1, doc2='I like dogs.', 'I hate dogs.'\n",
    "\n",
    "# Split the documents and create tokens\n",
    "doc1_tokens=set(doc1.lower().split())\n",
    "doc2_tokens=set(doc2.lower().split())\n",
    "\n",
    "#Print the tokens\n",
    "print(doc1_tokens,doc2_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "407baa63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "# Jaccard\n",
    "\n",
    "jaccard_sim = len(doc1_tokens.intersection(doc2_tokens))/len(doc1_tokens.union(doc2_tokens))\n",
    "\n",
    "print(jaccard_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "848a968f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.33609693]\n",
      " [0.33609693 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Cosine\n",
    "# Let's import text feature extraction TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Import Cosien Similarity metric\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "docs=['I like dogs.', 'I hate dogs.']\n",
    "\n",
    "# Create TFidfVectorizer \n",
    "tfidf= TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the documents \n",
    "tfidf_vector = tfidf.fit_transform(docs)\n",
    "\n",
    "# Compute cosine similarity\n",
    "cosine_sim=cosine_similarity(tfidf_vector, tfidf_vector)\n",
    "\n",
    "# Print the cosine similarity\n",
    "print(cosine_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3346017d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53a3c2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26010/2357117291.py:4: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  doc1.similarity(doc2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9454207125669349"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Document Vectorization\n",
    "doc1, doc2 = nlp('I like apples.'), nlp('I like oranges.')\n",
    "\n",
    "doc1.similarity(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd3132f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9454206228256226\n"
     ]
    }
   ],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "# Document Vectorization\n",
    "doc1, doc2 = nlp('I like apples.').vector, nlp('I like oranges.').vector\n",
    "\n",
    "# Cosine Similarity\n",
    "result = 1 - spatial.distance.cosine(doc1, doc2)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87222122",
   "metadata": {},
   "source": [
    "## Search Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4ded19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "\n",
    "# Prepare dataset\n",
    "doc_list=['I love this sandwich.',\n",
    "          'this is an amazing place!',\n",
    "          'I feel very good about these beers.',\n",
    "          'this is my best work.',\n",
    "          'what an awesome view',\n",
    "          'I do not like this restaurant',\n",
    "          'I am tired of this stuff.',\n",
    "          \"I can't deal with this\",\n",
    "          'he is my sworn enemy!',\n",
    "          'my boss is horrible.',\n",
    "          'I hate this sandwich.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f732677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "horrible\n"
     ]
    }
   ],
   "source": [
    "query = input()\n",
    "\n",
    "sim_list = []\n",
    "\n",
    "def cosine(vec1,vec2):\n",
    "    return dot(vec1,vec2) / (norm(vec1) * norm(vec2))\n",
    "\n",
    "for doc in doc_list:\n",
    "    vec1 = nlp(query).vector\n",
    "    vec2 = nlp(doc).vector\n",
    "    sim_score = cosine(vec1,vec2)\n",
    "    sim_list.append(sim_score)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c02a184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.22444192,\n",
       " 0.19761992,\n",
       " 0.25994086,\n",
       " 0.082769185,\n",
       " 0.18947649,\n",
       " -0.08410258,\n",
       " 0.2888038,\n",
       " -0.055111412,\n",
       " 0.20689178,\n",
       " 0.34992522,\n",
       " 0.2285129]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "93ada152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most Similar:\n",
      " my boss is horrible.\n"
     ]
    }
   ],
   "source": [
    "# most similar\n",
    "most_similar=doc_list[sim_list.index(max(sim_list))]\n",
    "print(\"\\nMost Similar:\\n\",most_similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fd3d2b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting most similar sentences\n",
    "top_index=list(np.argsort(sim_list)[-5:])\n",
    "\n",
    "top_index.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4ba6d182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my boss is horrible.\n",
      "I am tired of this stuff.\n",
      "I feel very good about these beers.\n",
      "I hate this sandwich.\n",
      "I love this sandwich.\n"
     ]
    }
   ],
   "source": [
    "for i in top_index:\n",
    "    print(doc_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f07487f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
